# 📘 Important Topics by Unit – Machine Learning

---

## ✅ Unit I: Introduction to Learning

### 📌 Important Topics:
- **Concept Learning**  
  - Candidate Elimination Algorithm  
  - Hypothesis Representation  
- **Version Spaces**  
  - How hypotheses shrink based on training data  
- **Finite vs Infinite Hypothesis Spaces**  
  - Definitions and differences  
- **PAC Learning** (Probably Approximately Correct)  
  - Sample complexity  
  - Generalization  
- **VC Dimension**  
  - Definition  
  - Use in understanding model capacity  

### 📝 Expected Questions:
- Define Concept Learning  
- Explain Version Space with example  
- What is PAC Learning?  
- Short note on VC dimension

---

## ✅ Unit II: Supervised Learning Algorithms

### 📌 Important Topics:
- **Learning a Class from Examples** – Generalization and overfitting  
- **Decision Trees**
  - ID3 (Information Gain)
  - CART (Gini Index)
- **Regression**
  - Linear Regression
  - Multiple Linear Regression
  - Logistic Regression (Sigmoid, Cost Function)
- **Neural Networks**
  - Perceptron Learning Rule
  - Multilayer Perceptron (MLP), Backpropagation
- **Support Vector Machines**
  - Linear vs Non-linear
  - Kernel Functions
- **K-Nearest Neighbors (KNN)**  
  - Working and pros/cons  

### 📝 Expected Questions:
- Construct a decision tree using ID3  
- Derive linear regression  
- Explain SVM with kernel function  
- Compare logistic vs linear regression  

---

## ✅ Unit III: Ensemble Learning

### 📌 Important Topics:
- **Voting Methods**
  - Majority voting, weighted voting  
- **Bagging**
  - Random Forest Trees  
- **Boosting**
  - AdaBoost algorithm (weight updates)  
- **Stacking**
  - Meta-learners and architecture  
- **Error-Correcting Output Codes (ECOC)**

### 📝 Expected Questions:
- Differentiate between Bagging and Boosting  
- Describe the AdaBoost algorithm  
- Explain stacking with an example  

---

## ✅ Unit IV: Unsupervised Learning

### 📌 Important Topics:
- **Clustering**
  - K-Means Clustering  
  - K-Modes Clustering (Categorical Data)  
  - Hierarchical Clustering: AGNES (Bottom-up) and DIANA (Top-down)  
- **Expectation Maximization (EM Algorithm)**
- **Gaussian Mixture Models (GMM)**
- **Principal Component Analysis (PCA)**
  - Eigenvalues/Eigenvectors, Dimensionality Reduction  
- **Locally Linear Embedding (LLE)**
- **Factor Analysis**

### 📝 Expected Questions:
- Explain K-means algorithm with example  
- Compare AGNES and DIANA  
- PCA derivation or its applications  

---

## ✅ Unit V: Probabilistic Learning

### 📌 Important Topics:
- **Bayesian Learning**
  - Bayes Theorem  
  - MAP and ML Hypothesis  
- **Naïve Bayes Classifier**
  - Assumptions, Laplace Smoothing  
- **Bayesian Belief Networks**
  - Structure and Conditional Probability Table (CPT)  
- **EM Algorithm**
  - Steps and applications in GMM  

### 📝 Expected Questions:
- Derive Naive Bayes classifier  
- Explain EM algorithm with steps  
- What is a Bayesian Belief Network?

---
